{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dadd2ab",
   "metadata": {},
   "source": [
    "# Proyecto Parte III - Gym dataset (Google Colab)\n",
    "\n",
    "Autor: `Perez`\n",
    "\n",
    "Objetivo: predecir la columna objetivo **`Workout type`** usando el dataset proporcionado `gym_members_exercise_tracking.csv`.\n",
    "\n",
    "Este notebook está listo para ejecutar en **Google Colab**. Contiene:\n",
    "1. Carga de datos (intenta usar el archivo incluido en el entorno).  \n",
    "2. Preprocesamiento (limpieza básica, codificación).  \n",
    "3. Feature selection (SelectKBest y SelectFromModel).  \n",
    "4. Entrenamiento de modelo de clasificación (RandomForest).  \n",
    "5. Métricas y validación (train/test + cross-validation).  \n",
    "6. Conclusiones y pasos para subir a GitHub.\n",
    "\n",
    "**Nota:** Si ejecutás en Colab y no subiste el archivo, usá el bloque de `files.upload()` que aparece abajo o montá Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370e13a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "print('Libraries loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854f5bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset: intenta cargar desde el path proporcionado\n",
    "fn = '/mnt/data/gym_members_exercise_tracking.csv'\n",
    "if os.path.exists(fn):\n",
    "    df = pd.read_csv(fn)\n",
    "    print('Dataset cargado desde', fn)\n",
    "else:\n",
    "    print('No se encontró el archivo en el entorno. Ejecutá este notebook en Colab y subí el archivo usando el bloque siguiente o montá Google Drive.')\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        print('\\nPor favor subí el archivo CSV ahora:')\n",
    "        uploaded = files.upload()\n",
    "        if len(uploaded) > 0:\n",
    "            name = list(uploaded.keys())[0]\n",
    "            df = pd.read_csv(name)\n",
    "            print('Dataset cargado desde uploaded file:', name)\n",
    "        else:\n",
    "            raise FileNotFoundError('No file uploaded')\n",
    "    except Exception as e:\n",
    "        print('Advertencia (no Colab?):', e)\n",
    "        rel = 'gym_members_exercise_tracking.csv'\n",
    "        if os.path.exists(rel):\n",
    "            df = pd.read_csv(rel)\n",
    "            print('Dataset cargado desde', rel)\n",
    "        else:\n",
    "            raise FileNotFoundError('Dataset no encontrado. Coloca gym_members_exercise_tracking.csv en el mismo directorio.')\n",
    "\n",
    "print('\\nShape del dataset:', df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20884e50",
   "metadata": {},
   "source": [
    "## Exploración rápida de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b98db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información y limpieza básica\n",
    "print('Columnas:')\n",
    "print(df.columns.tolist())\n",
    "\n",
    "print('\\nNulos por columna:')\n",
    "print(df.isna().sum())\n",
    "\n",
    "if 'Workout type' not in df.columns:\n",
    "    raise KeyError(\"La columna 'Workout type' no está en el dataset. Asegurate del nombre exacto (sensible a mayúsculas).\")\n",
    "\n",
    "print('\\nDistribución del target (Workout type):')\n",
    "print(df['Workout type'].value_counts())\n",
    "\n",
    "print('\\nTipos de datos:')\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b0e32e",
   "metadata": {},
   "source": [
    "## Preprocesamiento\n",
    "- Rellenar nulos simples\n",
    "- Codificar variables categóricas\n",
    "- Escalar numéricos si corresponde\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33acc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copiar df\n",
    "df_proc = df.copy()\n",
    "\n",
    "# Rellenar nulos: para columnas numéricas -> mediana; para categóricas -> 'missing'\n",
    "num_cols = df_proc.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "cat_cols = df_proc.select_dtypes(include=['object','category']).columns.tolist()\n",
    "\n",
    "for c in num_cols:\n",
    "    df_proc[c] = df_proc[c].fillna(df_proc[c].median())\n",
    "for c in cat_cols:\n",
    "    df_proc[c] = df_proc[c].astype('str').fillna('missing')\n",
    "\n",
    "# Separar X, y\n",
    "y = df_proc['Workout type']\n",
    "X = df_proc.drop(columns=['Workout type'])\n",
    "\n",
    "# Codificar categóricas con LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoders = {}\n",
    "for c in X.select_dtypes(include=['object','category']).columns:\n",
    "    le = LabelEncoder()\n",
    "    X[c] = le.fit_transform(X[c].astype(str))\n",
    "    encoders[c] = le\n",
    "\n",
    "# Codificar target\n",
    "le_target = LabelEncoder()\n",
    "y_enc = le_target.fit_transform(y.astype(str))\n",
    "\n",
    "print('Shape X:', X.shape)\n",
    "print('Target classes:', le_target.classes_)\n",
    "\n",
    "# Escalado opcional\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "num_in_X = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "X[num_in_X] = scaler.fit_transform(X[num_in_X])\n",
    "\n",
    "display(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f3e639",
   "metadata": {},
   "source": [
    "## Partición train / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6befd10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size=0.2, stratify=y_enc, random_state=42)\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ae4216",
   "metadata": {},
   "source": [
    "## Feature selection 1 — SelectKBest (mutual_info_classif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8038028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = min(15, X_train.shape[1])\n",
    "skb = SelectKBest(score_func=mutual_info_classif, k=k)\n",
    "skb.fit(X_train, y_train)\n",
    "cols_kbest = X_train.columns[skb.get_support()].tolist()\n",
    "print(f'Se seleccionaron {len(cols_kbest)} features con SelectKBest:')\n",
    "print(cols_kbest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73ec90d",
   "metadata": {},
   "source": [
    "## Feature selection 2 — SelectFromModel (RandomForest feature importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b63538",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_fs = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "rf_fs.fit(X_train, y_train)\n",
    "selector = SelectFromModel(rf_fs, prefit=True, threshold='median')\n",
    "cols_sfm = X_train.columns[selector.get_support()].tolist()\n",
    "print('Features seleccionadas por SelectFromModel (threshold=median):')\n",
    "print(cols_sfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf746a3",
   "metadata": {},
   "source": [
    "## Entrenamiento — RandomForestClassifier\n",
    "Entrenamos tres modelos: con todas las features, con SelectKBest y con SelectFromModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a81bd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(clf, X_tr, X_te, y_tr, y_te):\n",
    "    clf.fit(X_tr, y_tr)\n",
    "    y_pred = clf.predict(X_te)\n",
    "    scores = {\n",
    "        'accuracy': accuracy_score(y_te, y_pred),\n",
    "        'precision_macro': precision_score(y_te, y_pred, average='macro', zero_division=0),\n",
    "        'recall_macro': recall_score(y_te, y_pred, average='macro', zero_division=0),\n",
    "        'f1_macro': f1_score(y_te, y_pred, average='macro', zero_division=0)\n",
    "    }\n",
    "    print('Scores:', scores)\n",
    "    print('\\nClassification report:\\n', classification_report(y_te, y_pred, zero_division=0))\n",
    "    cm = confusion_matrix(y_te, y_pred)\n",
    "    return scores, cm\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1)\n",
    "\n",
    "print('--- All features ---')\n",
    "s_all, cm_all = train_and_eval(rf, X_train, X_test, y_train, y_test)\n",
    "\n",
    "print('\\n--- SelectKBest ---')\n",
    "X_train_k = skb.transform(X_train)\n",
    "X_test_k = skb.transform(X_test)\n",
    "s_k, cm_k = train_and_eval(rf, X_train_k, X_test_k, y_train, y_test)\n",
    "\n",
    "print('\\n--- SelectFromModel ---')\n",
    "X_train_s = selector.transform(X_train)\n",
    "X_test_s = selector.transform(X_test)\n",
    "s_s, cm_s = train_and_eval(rf, X_train_s, X_test_s, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4bdc63",
   "metadata": {},
   "source": [
    "## Validación cruzada (StratifiedKFold, 5 folds) — comparar F1 macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45023d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def cv_f1(clf, X_all, y_all):\n",
    "    return cross_val_score(clf, X_all, y_all, cv=cv, scoring='f1_macro')\n",
    "\n",
    "print('CV F1 (all):', cv_f1(rf, X, y_enc).mean())\n",
    "print('CV F1 (SelectKBest):', cv_f1(rf, skb.transform(X), y_enc).mean())\n",
    "print('CV F1 (SelectFromModel):', cv_f1(rf, selector.transform(X), y_enc).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51d84ab",
   "metadata": {},
   "source": [
    "## Matrices de confusión (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e03f41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(cm, title):\n",
    "    plt.figure(figsize=(5,4))\n",
    "    plt.imshow(cm, interpolation='nearest')\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, cm[i, j], ha='center', va='center')\n",
    "    plt.show()\n",
    "\n",
    "plot_cm(cm_all, 'Confusion matrix - All features')\n",
    "plot_cm(cm_k, 'Confusion matrix - SelectKBest')\n",
    "plot_cm(cm_s, 'Confusion matrix - SelectFromModel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7d3b3a",
   "metadata": {},
   "source": [
    "## Importancias de features (RandomForest usado para SelectFromModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054e7a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf_fs.feature_importances_\n",
    "imp_df = pd.DataFrame({'feature': X_train.columns, 'importance': importances}).sort_values('importance', ascending=False)\n",
    "imp_df_top = imp_df.head(20)\n",
    "print(imp_df_top)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(imp_df_top['feature'], imp_df_top['importance'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Top feature importances')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a45b95",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "- Se compararon dos métodos de selección de features y un clasificador RandomForest.  \n",
    "- Interpretá los resultados: fijate si con menos features (SelectKBest/SelectFromModel) mantenemos una métrica `f1_macro` cercana a la de usar todas las features.  \n",
    "- Si la reducción mantiene rendimiento, preferible por interpretabilidad y menor costo computacional.\n",
    "\n",
    "### Entrega en GitHub\n",
    "1. Subí este notebook `ProyectoParteIII_Perez.ipynb` a tu repositorio.\n",
    "2. Subí también el archivo `gym_members_exercise_tracking.csv`.\n",
    "3. Agregá un `README.md` que explique cómo ejecutar (por ejemplo: abrir en Colab y subir el CSV o montar Drive).\n",
    "\n",
    "---\n",
    "\n",
    "Listo: el notebook está preparado para ejecutar en Colab. Ajustá hiperparámetros o métodos (p. ej. probar XGBoost o SVM) si lo deseás."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
